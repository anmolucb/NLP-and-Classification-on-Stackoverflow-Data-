{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8382c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a29daf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('stack_stats_2020_train.csv')\n",
    "testing = pd.read_csv('stack_stats_2020_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f8e959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495560</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;I have a set of data that I am transforming...</td>\n",
       "      <td>R: emmeans back tranform clr data using clrInv</td>\n",
       "      <td>&lt;r&gt;&lt;mixed-model&gt;&lt;linear&gt;&lt;lsmeans&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489896</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;We are sending a one bit message to someone...</td>\n",
       "      <td>Trying to determine the failure rate of redund...</td>\n",
       "      <td>&lt;probability&gt;&lt;python&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>497951</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;I am aware that there is a similar post: &lt;a...</td>\n",
       "      <td>How to derive categorical cross entropy update...</td>\n",
       "      <td>&lt;logistic&gt;&lt;cross-entropy&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>478542</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;I have a Poisson distributed glm where I ha...</td>\n",
       "      <td>Learning more about glm parameters, how to dig...</td>\n",
       "      <td>&lt;generalized-linear-model&gt;&lt;interpretation&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>458388</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;1) how do i decide which transformation or ...</td>\n",
       "      <td>Is there I guide to decide which transformatio...</td>\n",
       "      <td>&lt;python&gt;&lt;data-transformation&gt;&lt;dataset&gt;&lt;feature...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Score                                               Body  \\\n",
       "0  495560      1  <p>I have a set of data that I am transforming...   \n",
       "1  489896      0  <p>We are sending a one bit message to someone...   \n",
       "2  497951      2  <p>I am aware that there is a similar post: <a...   \n",
       "3  478542      2  <p>I have a Poisson distributed glm where I ha...   \n",
       "4  458388      0  <p>1) how do i decide which transformation or ...   \n",
       "\n",
       "                                               Title  \\\n",
       "0     R: emmeans back tranform clr data using clrInv   \n",
       "1  Trying to determine the failure rate of redund...   \n",
       "2  How to derive categorical cross entropy update...   \n",
       "3  Learning more about glm parameters, how to dig...   \n",
       "4  Is there I guide to decide which transformatio...   \n",
       "\n",
       "                                                Tags  \n",
       "0                  <r><mixed-model><linear><lsmeans>  \n",
       "1                              <probability><python>  \n",
       "2                          <logistic><cross-entropy>  \n",
       "3         <generalized-linear-model><interpretation>  \n",
       "4  <python><data-transformation><dataset><feature...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stackoverflowdata\n",
    "#joining test and train data to make it easier to pre-process and clean all the data at one and then split them later on\n",
    "stack_data = pd.concat([training, testing])\n",
    "stack_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a052fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_data['UsefulQuestion'] = (stack_data['Score'] >= 1).astype('int32').astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "287a26d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "8244    0\n",
       "8245    1\n",
       "8246    1\n",
       "8247    1\n",
       "8248    1\n",
       "Name: UsefulQuestion, Length: 27496, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_data['UsefulQuestion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b33bf",
   "metadata": {},
   "source": [
    "### To extract text and remove tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcd5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that turns html text into plain text\n",
    "def html_text(table, column):\n",
    "    plain_html = []\n",
    "    for index, row in column.iteritems():\n",
    "        each = BeautifulSoup(row)\n",
    "        plain_html.append(each.get_text())\n",
    "        #print(column.row)\n",
    "    table['Plain_Text'] = plain_html\n",
    "    return table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d789394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>UsefulQuestion</th>\n",
       "      <th>Plain_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495560</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;I have a set of data that I am transforming...</td>\n",
       "      <td>R: emmeans back tranform clr data using clrInv</td>\n",
       "      <td>&lt;r&gt;&lt;mixed-model&gt;&lt;linear&gt;&lt;lsmeans&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>I have a set of data that I am transforming us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489896</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;We are sending a one bit message to someone...</td>\n",
       "      <td>Trying to determine the failure rate of redund...</td>\n",
       "      <td>&lt;probability&gt;&lt;python&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>We are sending a one bit message to someone.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>497951</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;I am aware that there is a similar post: &lt;a...</td>\n",
       "      <td>How to derive categorical cross entropy update...</td>\n",
       "      <td>&lt;logistic&gt;&lt;cross-entropy&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>I am aware that there is a similar post: Vecto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>478542</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;I have a Poisson distributed glm where I ha...</td>\n",
       "      <td>Learning more about glm parameters, how to dig...</td>\n",
       "      <td>&lt;generalized-linear-model&gt;&lt;interpretation&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>I have a Poisson distributed glm where I have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>458388</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;1) how do i decide which transformation or ...</td>\n",
       "      <td>Is there I guide to decide which transformatio...</td>\n",
       "      <td>&lt;python&gt;&lt;data-transformation&gt;&lt;dataset&gt;&lt;feature...</td>\n",
       "      <td>0</td>\n",
       "      <td>1) how do i decide which transformation or sca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Score                                               Body  \\\n",
       "0  495560      1  <p>I have a set of data that I am transforming...   \n",
       "1  489896      0  <p>We are sending a one bit message to someone...   \n",
       "2  497951      2  <p>I am aware that there is a similar post: <a...   \n",
       "3  478542      2  <p>I have a Poisson distributed glm where I ha...   \n",
       "4  458388      0  <p>1) how do i decide which transformation or ...   \n",
       "\n",
       "                                               Title  \\\n",
       "0     R: emmeans back tranform clr data using clrInv   \n",
       "1  Trying to determine the failure rate of redund...   \n",
       "2  How to derive categorical cross entropy update...   \n",
       "3  Learning more about glm parameters, how to dig...   \n",
       "4  Is there I guide to decide which transformatio...   \n",
       "\n",
       "                                                Tags UsefulQuestion  \\\n",
       "0                  <r><mixed-model><linear><lsmeans>              1   \n",
       "1                              <probability><python>              0   \n",
       "2                          <logistic><cross-entropy>              1   \n",
       "3         <generalized-linear-model><interpretation>              1   \n",
       "4  <python><data-transformation><dataset><feature...              0   \n",
       "\n",
       "                                          Plain_Text  \n",
       "0  I have a set of data that I am transforming us...  \n",
       "1  We are sending a one bit message to someone.  ...  \n",
       "2  I am aware that there is a similar post: Vecto...  \n",
       "3  I have a Poisson distributed glm where I have ...  \n",
       "4  1) how do i decide which transformation or sca...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_text(stack_data, stack_data['Body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a5e04",
   "metadata": {},
   "source": [
    "### To remove the \\n from the body text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9f4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# re has expressions to search and manipulate strings\n",
    "\n",
    "\n",
    "column1 = []\n",
    "for values in stack_data['Plain_Text']:\n",
    "    column1.append(re.sub('\\\\n', ' ', values))\n",
    "stack_data['Plainer_Text'] = column1\n",
    "\n",
    "column2 = []\n",
    "for values in stack_data['Plainer_Text']:\n",
    "    column2.append(re.sub('\\#', ' ', values))\n",
    "stack_data['Plainer_Text'] = column2\n",
    "\n",
    "column3 = []\n",
    "for values in stack_data['Plainer_Text']:\n",
    "    column3.append(re.sub('(\\$.*?\\$)', ' ', values))\n",
    "stack_data['Plainer_Text'] = column3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae02e9",
   "metadata": {},
   "source": [
    "### Text Cleaning: Body column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a6b294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodytext = stack_data['Plainer_Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2117e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing to lowercase\n",
    "body_lowercase_test = bodytext.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48137525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuation marks\n",
    "from string import punctuation\n",
    "\n",
    "def remove_punctuation(document):\n",
    "    no_punct = ''.join([character for character in document if character not in punctuation])\n",
    "    return no_punct\n",
    "\n",
    "text_body_no_punct = body_lowercase_test.apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8a20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3b0af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7bd25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anmol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#remove stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db2fd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [i, have, a, set, of, data, that, i, am, trans...\n",
       "1       [we, are, sending, a, one, bit, message, to, s...\n",
       "2       [i, am, aware, that, there, is, a, similar, po...\n",
       "3       [i, have, a, poisson, distributed, glm, where,...\n",
       "4       [1, how, do, i, decide, which, transformation,...\n",
       "                              ...                        \n",
       "8244    [my, data, is, of, the, form, where, i, denote...\n",
       "8245    [i, noticed, the, term, anova, used, in, many,...\n",
       "8246    [im, trying, to, do, logistic, regression, but...\n",
       "8247    [consider, the, following, experimental, desig...\n",
       "8248    [i, am, constructing, different, configuration...\n",
       "Name: Plainer_Text, Length: 27496, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_text_body = text_body_no_punct.apply(word_tokenize)\n",
    "tokenized_text_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38aa157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(document):\n",
    "    words = [word for word in document if not word in stop_words]\n",
    "    return words\n",
    "body_no_stopword_text = tokenized_text_body.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab17c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96814daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def stemmer(document):\n",
    "    stemmed_document = [porter.stem(word) for word in document]\n",
    "    return stemmed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07f9e350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [set, data, transform, use, clr, function, lib...\n",
       "1       [send, one, bit, messag, someon, 60, chanc, me...\n",
       "2       [awar, similar, post, vector, cross, entropi, ...\n",
       "3       [poisson, distribut, glm, identifi, origin, pa...\n",
       "4       [1, decid, transform, scale, use, pass, data, ...\n",
       "                              ...                        \n",
       "8244    [data, form, denot, compon, independ, variabl,...\n",
       "8245    [notic, term, anova, use, mani, context, one, ...\n",
       "8246    [im, tri, logist, regress, cant, seem, get, re...\n",
       "8247    [consid, follow, experiment, design, withinsub...\n",
       "8248    [construct, differ, configur, random, forest, ...\n",
       "Name: Plainer_Text, Length: 27496, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_body_stemmed = body_no_stopword_text.apply(stemmer)\n",
    "text_body_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b23732",
   "metadata": {},
   "source": [
    "### Document term matrix- Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd296c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detokenization\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "text_body_detokenized = text_body_stemmed.apply(TreebankWordDetokenizer().detokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74168639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27496x908 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1042114 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dtm\n",
    "#seting min_df to 0.05 to preserve as many words as possible and elimination of irrelevant number\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvec = CountVectorizer(min_df=0.01)\n",
    "\n",
    "sparse_dtm_body = countvec.fit_transform(text_body_detokenized)\n",
    "sparse_dtm_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bcc30b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0001</th>\n",
       "      <th>001</th>\n",
       "      <th>005</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>xi</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>yield</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 908 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0001  001  005  01  02  05  10  100  1000  10000  ...  written  wrong  x1  \\\n",
       "0     0    0    0   0   0   0   0    0     0      0  ...        0      0   0   \n",
       "1     0    0    1   0   0   0   0    0     0      0  ...        0      0   0   \n",
       "2     0    0    0   0   0   0   1    0     0      0  ...        0      0   0   \n",
       "3     0    0    0   0   0   0   0    0     0      0  ...        0      0   0   \n",
       "4     0    0    0   0   0   0   0    0     0      0  ...        0      0   0   \n",
       "\n",
       "   x2  xi  ye  year  yet  yield  zero  \n",
       "0   0   0   0     0    0      0     0  \n",
       "1   0   0   0     0    0      0     0  \n",
       "2   0   0   0     0    1      0     0  \n",
       "3   0   0   0     0    0      0     0  \n",
       "4   0   0   0     0    0      0     0  \n",
       "\n",
       "[5 rows x 908 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_body = pd.DataFrame(sparse_dtm_body.toarray(), columns=countvec.get_feature_names_out(), index=stack_data.index)\n",
    "dtm_body.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c56aedc",
   "metadata": {},
   "source": [
    "### Text Cleaning Title of the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6011efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text = stack_data['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcaf8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to lowercase\n",
    "title_text_lowercase = title_text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e06b6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "title_text_no_punct = title_text_lowercase.apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bd85120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [r, emmeans, back, tranform, clr, data, using,...\n",
       "1    [trying, to, determine, the, failure, rate, of...\n",
       "2    [how, to, derive, categorical, cross, entropy,...\n",
       "3    [learning, more, about, glm, parameters, how, ...\n",
       "4    [is, there, i, guide, to, decide, which, trans...\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizing the text\n",
    "title_text_tokenized = title_text_no_punct.apply(word_tokenize)\n",
    "title_text_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cbb70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all stop words from the text\n",
    "title_no_stopwords = title_text_tokenized.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e1b5223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [r, emmean, back, tranform, clr, data, use, cl...\n",
       "1       [tri, determin, failur, rate, redundantli, sen...\n",
       "2       [deriv, categor, cross, entropi, updat, rule, ...\n",
       "3                      [learn, glm, paramet, dig, deeper]\n",
       "4       [guid, decid, transform, choos, differ, scenar...\n",
       "                              ...                        \n",
       "8244                    [visualis, high, dimension, data]\n",
       "8245    [analysi, residu, varianc, still, anova, regre...\n",
       "8246                 [handl, miss, data, logist, regress]\n",
       "8247    [mix, model, treat, random, factor, nest, with...\n",
       "8248                        [data, partit, spatial, data]\n",
       "Name: Title, Length: 27496, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming the text present in title\n",
    "title_text_stemmed = title_no_stopwords.apply(stemmer)\n",
    "title_text_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b21102",
   "metadata": {},
   "source": [
    "### Document Term Matrix - Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a45a93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text_detokenized = title_text_stemmed.apply(TreebankWordDetokenizer().detokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6a60dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27496x109 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 74395 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvec = CountVectorizer(min_df=0.01)\n",
    "\n",
    "sparse_dtm_title = countvec.fit_transform(title_text_detokenized)\n",
    "sparse_dtm_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d33e517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>analysi</th>\n",
       "      <th>anova</th>\n",
       "      <th>base</th>\n",
       "      <th>bayesian</th>\n",
       "      <th>best</th>\n",
       "      <th>binari</th>\n",
       "      <th>binomi</th>\n",
       "      <th>calcul</th>\n",
       "      <th>categor</th>\n",
       "      <th>...</th>\n",
       "      <th>two</th>\n",
       "      <th>understand</th>\n",
       "      <th>use</th>\n",
       "      <th>valid</th>\n",
       "      <th>valu</th>\n",
       "      <th>variabl</th>\n",
       "      <th>varianc</th>\n",
       "      <th>vs</th>\n",
       "      <th>way</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithm  analysi  anova  base  bayesian  best  binari  binomi  calcul  \\\n",
       "0          0        0      0     0         0     0       0       0       0   \n",
       "1          0        0      0     0         0     0       0       0       0   \n",
       "2          0        0      0     0         0     0       0       0       0   \n",
       "3          0        0      0     0         0     0       0       0       0   \n",
       "4          0        0      0     0         0     0       0       0       0   \n",
       "\n",
       "   categor  ...  two  understand  use  valid  valu  variabl  varianc  vs  way  \\\n",
       "0        0  ...    0           0    1      0     0        0        0   0    0   \n",
       "1        0  ...    0           0    0      0     0        0        0   0    0   \n",
       "2        1  ...    0           0    0      0     0        0        0   0    0   \n",
       "3        0  ...    0           0    0      0     0        0        0   0    0   \n",
       "4        0  ...    0           0    0      0     0        0        0   0    0   \n",
       "\n",
       "   weight  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_title = pd.DataFrame(sparse_dtm_title.toarray(), columns=countvec.get_feature_names_out(), index=stack_data.index)\n",
    "dtm_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf575a88",
   "metadata": {},
   "source": [
    "### Text Cleaning: Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fac016ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_text = stack_data['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91658ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    <r><mixed-model><linear><lsmeans>\n",
       "1                                <probability><python>\n",
       "2                            <logistic><cross-entropy>\n",
       "3           <generalized-linear-model><interpretation>\n",
       "4    <python><data-transformation><dataset><feature...\n",
       "Name: Tags, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change to lowercase\n",
    "text_tags_lowercase = tags_text.str.lower()\n",
    "text_tags_lowercase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0471ca1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       [r, mixed-model, linear, lsmeans]\n",
       "1                                   [probability, python]\n",
       "2                               [logistic, cross-entropy]\n",
       "3              [generalized-linear-model, interpretation]\n",
       "4       [python, data-transformation, dataset, feature...\n",
       "                              ...                        \n",
       "8244                     [r, data-visualization, ggplot2]\n",
       "8245    [regression, anova, generalized-linear-model, ...\n",
       "8246    [r, regression, logistic, missing-data, regres...\n",
       "8247                          [r, mixed-model, lme4-nlme]\n",
       "8248    [machine-learning, random-forest, spatial, par...\n",
       "Name: Tags, Length: 27496, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove \"< >\"\n",
    "import re\n",
    "\n",
    "new_tags = []\n",
    "for values in text_tags_lowercase:\n",
    "    new_tags.append(re.findall('<(.*?)>', values))\n",
    "stack_data['Tags'] = new_tags\n",
    "\n",
    "stack_data['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d45a2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "tag_text_no_punct = text_tags_lowercase.apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2058fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           [rmixedmodellinearlsmeans]\n",
       "1                                  [probabilitypython]\n",
       "2                               [logisticcrossentropy]\n",
       "3               [generalizedlinearmodelinterpretation]\n",
       "4    [pythondatatransformationdatasetfeatureenginee...\n",
       "Name: Tags, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizing the text\n",
    "tag_text_tokenized = tag_text_no_punct.apply(word_tokenize)\n",
    "tag_text_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66adcd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all stop words from the text\n",
    "tag_no_stopwords = tag_text_tokenized.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "835cae4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               [rmixedmodellinearlsmean]\n",
       "1                                     [probabilitypython]\n",
       "2                                  [logisticcrossentropi]\n",
       "3                       [generalizedlinearmodelinterpret]\n",
       "4       [pythondatatransformationdatasetfeatureenginee...\n",
       "                              ...                        \n",
       "8244                          [rdatavisualizationggplot2]\n",
       "8245    [regressionanovageneralizedlinearmodelmodeling...\n",
       "8246    [rregressionlogisticmissingdataregressionstrat...\n",
       "8247                                 [rmixedmodellme4nlm]\n",
       "8248    [machinelearningrandomforestspatialpartitionin...\n",
       "Name: Tags, Length: 27496, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming the text present in title\n",
    "tag_text_stemmed = tag_no_stopwords.apply(stemmer)\n",
    "tag_text_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5456b155",
   "metadata": {},
   "source": [
    "### Document Term Matrix - Tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a34d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_text_detokenized = tag_text_stemmed.apply(TreebankWordDetokenizer().detokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c15130e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27496x784 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4866 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvec = CountVectorizer(min_df=0.0001)\n",
    "\n",
    "sparse_dtm_tag = countvec.fit_transform(tag_text_detokenized)\n",
    "sparse_dtm_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4662d77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agreementstatist</th>\n",
       "      <th>agreementstatisticscohenskappa</th>\n",
       "      <th>aic</th>\n",
       "      <th>aicbic</th>\n",
       "      <th>anova</th>\n",
       "      <th>anovacontrast</th>\n",
       "      <th>anovainteract</th>\n",
       "      <th>anovalme4nlm</th>\n",
       "      <th>anovamixedmodel</th>\n",
       "      <th>anovaposthoc</th>\n",
       "      <th>...</th>\n",
       "      <th>tsne</th>\n",
       "      <th>ttest</th>\n",
       "      <th>ttestpaireddata</th>\n",
       "      <th>uncertaintyerrorpropag</th>\n",
       "      <th>varianc</th>\n",
       "      <th>variancecovari</th>\n",
       "      <th>varianceleastsquar</th>\n",
       "      <th>variancestandarddevi</th>\n",
       "      <th>wilcoxonmannwhitneytest</th>\n",
       "      <th>wilcoxonsignedrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   agreementstatist  agreementstatisticscohenskappa  aic  aicbic  anova  \\\n",
       "0                 0                               0    0       0      0   \n",
       "1                 0                               0    0       0      0   \n",
       "2                 0                               0    0       0      0   \n",
       "3                 0                               0    0       0      0   \n",
       "4                 0                               0    0       0      0   \n",
       "\n",
       "   anovacontrast  anovainteract  anovalme4nlm  anovamixedmodel  anovaposthoc  \\\n",
       "0              0              0             0                0             0   \n",
       "1              0              0             0                0             0   \n",
       "2              0              0             0                0             0   \n",
       "3              0              0             0                0             0   \n",
       "4              0              0             0                0             0   \n",
       "\n",
       "   ...  tsne  ttest  ttestpaireddata  uncertaintyerrorpropag  varianc  \\\n",
       "0  ...     0      0                0                       0        0   \n",
       "1  ...     0      0                0                       0        0   \n",
       "2  ...     0      0                0                       0        0   \n",
       "3  ...     0      0                0                       0        0   \n",
       "4  ...     0      0                0                       0        0   \n",
       "\n",
       "   variancecovari  varianceleastsquar  variancestandarddevi  \\\n",
       "0               0                   0                     0   \n",
       "1               0                   0                     0   \n",
       "2               0                   0                     0   \n",
       "3               0                   0                     0   \n",
       "4               0                   0                     0   \n",
       "\n",
       "   wilcoxonmannwhitneytest  wilcoxonsignedrank  \n",
       "0                        0                   0  \n",
       "1                        0                   0  \n",
       "2                        0                   0  \n",
       "3                        0                   0  \n",
       "4                        0                   0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_tag = pd.DataFrame(sparse_dtm_tag.toarray(), columns=countvec.get_feature_names_out(), index=stack_data.index)\n",
    "dtm_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "012d6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_body = dtm_body.add_suffix('_body')\n",
    "dtm_title = dtm_title.add_suffix('_title')\n",
    "dtm_tag = dtm_tag.add_suffix('_tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec28212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_title_joined = dtm_body.join(dtm_title)\n",
    "body_title_tag_joined = body_title_joined.join(dtm_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03d42e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0001_body</th>\n",
       "      <th>001_body</th>\n",
       "      <th>005_body</th>\n",
       "      <th>01_body</th>\n",
       "      <th>02_body</th>\n",
       "      <th>05_body</th>\n",
       "      <th>10_body</th>\n",
       "      <th>100_body</th>\n",
       "      <th>1000_body</th>\n",
       "      <th>10000_body</th>\n",
       "      <th>...</th>\n",
       "      <th>tsne_tags</th>\n",
       "      <th>ttest_tags</th>\n",
       "      <th>ttestpaireddata_tags</th>\n",
       "      <th>uncertaintyerrorpropag_tags</th>\n",
       "      <th>varianc_tags</th>\n",
       "      <th>variancecovari_tags</th>\n",
       "      <th>varianceleastsquar_tags</th>\n",
       "      <th>variancestandarddevi_tags</th>\n",
       "      <th>wilcoxonmannwhitneytest_tags</th>\n",
       "      <th>wilcoxonsignedrank_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19242</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19243</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19244</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19245</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76990 rows × 1801 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0001_body  001_body  005_body  01_body  02_body  05_body  10_body  \\\n",
       "0              0         0         0        0        0        0        0   \n",
       "0              0         0         0        0        0        0        0   \n",
       "0              0         0         0        0        0        0        0   \n",
       "0              0         0         0        0        0        0        0   \n",
       "0              0         0         0        0        0        0        0   \n",
       "...          ...       ...       ...      ...      ...      ...      ...   \n",
       "19242          0         0         0        0        0        0        0   \n",
       "19243          0         0         0        0        0        0        0   \n",
       "19244          0         0         0        0        0        0        0   \n",
       "19245          0         0         0        0        0        0        0   \n",
       "19246          0         0         0        0        0        0        0   \n",
       "\n",
       "       100_body  1000_body  10000_body  ...  tsne_tags  ttest_tags  \\\n",
       "0             0          0           0  ...          0           0   \n",
       "0             0          0           0  ...          0           0   \n",
       "0             0          0           0  ...          0           0   \n",
       "0             0          0           0  ...          0           0   \n",
       "0             0          0           0  ...          0           0   \n",
       "...         ...        ...         ...  ...        ...         ...   \n",
       "19242         0          0           0  ...          0           0   \n",
       "19243         0          0           0  ...          0           0   \n",
       "19244         0          0           0  ...          0           0   \n",
       "19245         0          0           0  ...          0           0   \n",
       "19246         0          0           0  ...          0           0   \n",
       "\n",
       "       ttestpaireddata_tags  uncertaintyerrorpropag_tags  varianc_tags  \\\n",
       "0                         0                            0             0   \n",
       "0                         0                            0             0   \n",
       "0                         0                            0             0   \n",
       "0                         0                            0             0   \n",
       "0                         0                            0             0   \n",
       "...                     ...                          ...           ...   \n",
       "19242                     0                            0             0   \n",
       "19243                     0                            0             0   \n",
       "19244                     0                            0             0   \n",
       "19245                     0                            0             0   \n",
       "19246                     0                            0             0   \n",
       "\n",
       "       variancecovari_tags  varianceleastsquar_tags  \\\n",
       "0                        0                        0   \n",
       "0                        0                        0   \n",
       "0                        0                        0   \n",
       "0                        0                        0   \n",
       "0                        0                        0   \n",
       "...                    ...                      ...   \n",
       "19242                    0                        0   \n",
       "19243                    0                        0   \n",
       "19244                    0                        0   \n",
       "19245                    0                        0   \n",
       "19246                    0                        0   \n",
       "\n",
       "       variancestandarddevi_tags  wilcoxonmannwhitneytest_tags  \\\n",
       "0                              0                             0   \n",
       "0                              0                             0   \n",
       "0                              0                             0   \n",
       "0                              0                             0   \n",
       "0                              0                             0   \n",
       "...                          ...                           ...   \n",
       "19242                          0                             0   \n",
       "19243                          0                             0   \n",
       "19244                          0                             0   \n",
       "19245                          0                             0   \n",
       "19246                          0                             0   \n",
       "\n",
       "       wilcoxonsignedrank_tags  \n",
       "0                            0  \n",
       "0                            0  \n",
       "0                            0  \n",
       "0                            0  \n",
       "0                            0  \n",
       "...                        ...  \n",
       "19242                        0  \n",
       "19243                        0  \n",
       "19244                        0  \n",
       "19245                        0  \n",
       "19246                        0  \n",
       "\n",
       "[76990 rows x 1801 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#impp\n",
    "body_title_tag_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6edb065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>UsefulQuestion</th>\n",
       "      <th>0001_body</th>\n",
       "      <th>001_body</th>\n",
       "      <th>005_body</th>\n",
       "      <th>01_body</th>\n",
       "      <th>02_body</th>\n",
       "      <th>05_body</th>\n",
       "      <th>10_body</th>\n",
       "      <th>...</th>\n",
       "      <th>tsne_tags</th>\n",
       "      <th>ttest_tags</th>\n",
       "      <th>ttestpaireddata_tags</th>\n",
       "      <th>uncertaintyerrorpropag_tags</th>\n",
       "      <th>varianc_tags</th>\n",
       "      <th>variancecovari_tags</th>\n",
       "      <th>varianceleastsquar_tags</th>\n",
       "      <th>variancestandarddevi_tags</th>\n",
       "      <th>wilcoxonmannwhitneytest_tags</th>\n",
       "      <th>wilcoxonsignedrank_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1804 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Score UsefulQuestion  0001_body  001_body  005_body  01_body  \\\n",
       "0  495560      1              1          0         0         0        0   \n",
       "0  495560      1              1          0         0         0        0   \n",
       "0  495560      1              1          0         0         0        0   \n",
       "0  495560      1              1          0         0         0        0   \n",
       "0  495560      1              1          0         0         0        0   \n",
       "\n",
       "   02_body  05_body  10_body  ...  tsne_tags  ttest_tags  \\\n",
       "0        0        0        0  ...          0           0   \n",
       "0        0        0        0  ...          0           0   \n",
       "0        0        0        0  ...          0           0   \n",
       "0        0        0        0  ...          0           0   \n",
       "0        0        0        0  ...          0           0   \n",
       "\n",
       "   ttestpaireddata_tags  uncertaintyerrorpropag_tags  varianc_tags  \\\n",
       "0                     0                            0             0   \n",
       "0                     0                            0             0   \n",
       "0                     0                            0             0   \n",
       "0                     0                            0             0   \n",
       "0                     0                            0             0   \n",
       "\n",
       "   variancecovari_tags  varianceleastsquar_tags  variancestandarddevi_tags  \\\n",
       "0                    0                        0                          0   \n",
       "0                    0                        0                          0   \n",
       "0                    0                        0                          0   \n",
       "0                    0                        0                          0   \n",
       "0                    0                        0                          0   \n",
       "\n",
       "   wilcoxonmannwhitneytest_tags  wilcoxonsignedrank_tags  \n",
       "0                             0                        0  \n",
       "0                             0                        0  \n",
       "0                             0                        0  \n",
       "0                             0                        0  \n",
       "0                             0                        0  \n",
       "\n",
       "[5 rows x 1804 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_data_processed = stack_data[['Id','Score','UsefulQuestion']].join(body_title_tag_joined)\n",
    "stack_data_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a743accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_data_processed.to_csv('stack_data_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a05cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f5de29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=stack_data_processed[0:19249]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064fea50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1e7b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set=stack_data_processed[19249:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90db02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b109216",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.66 GiB for an array with shape (1803, 123733) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m training_set\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m621\u001b[39m]\n\u001b[0;32m      2\u001b[0m x_train \u001b[38;5;241m=\u001b[39m training_set[feature_cols]\n\u001b[1;32m----> 3\u001b[0m x_test \u001b[38;5;241m=\u001b[39m \u001b[43mtesting_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m y_train \u001b[38;5;241m=\u001b[39m training_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsefulQuestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m y_test \u001b[38;5;241m=\u001b[39m testing_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsefulQuestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3517\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   3515\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(indexer)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 3517\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[0;32m   3520\u001b[0m     \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[0;32m   3521\u001b[0m     \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[0;32m   3522\u001b[0m     \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[0;32m   3523\u001b[0m     \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[0;32m   3524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[0;32m   3525\u001b[0m         \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3716\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3709\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3710\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3711\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3714\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3715\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3716\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3717\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3701\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3692\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   3693\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_copy is deprecated and will be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3694\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m always returns a copy, so there is no need to specify this.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3695\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   3696\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   3697\u001b[0m     )\n\u001b[0;32m   3699\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_take((), kwargs)\n\u001b[1;32m-> 3701\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3703\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[0;32m   3704\u001b[0m     indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis), verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3705\u001b[0m )\n\u001b[0;32m   3706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5653\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5650\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[0;32m   5651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mconsolidate()\n\u001b[1;32m-> 5653\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_protect_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5641\u001b[0m, in \u001b[0;36mNDFrame._protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f()\n\u001b[0;32m   5640\u001b[0m blocks_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[1;32m-> 5641\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks) \u001b[38;5;241m!=\u001b[39m blocks_before:\n\u001b[0;32m   5643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5651\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace.<locals>.f\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5650\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[1;32m-> 5651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:631\u001b[0m, in \u001b[0;36mBaseBlockManager.consolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    629\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    630\u001b[0m bm\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m \u001b[43mbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1685\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1686\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2084\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2082\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2084\u001b[0m     merged_blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2085\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2086\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2087\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_blocks\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2118\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2115\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2117\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2118\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2119\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2121\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.66 GiB for an array with shape (1803, 123733) and data type int64"
     ]
    }
   ],
   "source": [
    "feature_cols = training_set.columns[3:621]\n",
    "x_train = training_set[feature_cols]\n",
    "x_test = testing_set[feature_cols]\n",
    "y_train = training_set['UsefulQuestion']\n",
    "y_test = testing_set['UsefulQuestion']\n",
    "\n",
    "x_train=x_train.to_numpy().astype('int32')\n",
    "y_train=y_train.to_numpy().astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ed463",
   "metadata": {},
   "source": [
    "## Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee26344",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels==0.13.0\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = stack_data_processed['UsefulQuestion'][0:76990].astype('int32')\n",
    "X = body_title_tag_joined\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=88)\n",
    "X_train.shape, X_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba676afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(random_state=88)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c72b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_prob = logreg.predict_proba(X_test)\n",
    "y_pred = pd.Series([1 if x > 0.5 else 0 for x in y_prob[:,1]], index=y_test.index)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix: \\n\", cm)\n",
    "print (\"\\nAccuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57513de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7351dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lda = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "lda_confusion = confusion_matrix(y_test, y_pred_lda).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf749f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135cbd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validation to get the optimal ccp alpha\n",
    "#fits reduced from 2010 (demonstrated in lab) to 110 & max_depth from 30 to 20 for sake of time\n",
    "\n",
    "\n",
    "grid_values = {'ccp_alpha':np.linspace(0, 0.10, 11),\n",
    "               'min_samples_leaf': [5],\n",
    "               'min_samples_split': [20],\n",
    "               'max_depth': [20],\n",
    "               'random_state': [88]}\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc_cv_acc = GridSearchCV(dtc, param_grid = grid_values, cv = 10, verbose = 1, scoring = 'accuracy')\n",
    "dtc_cv_acc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derive the top 10 ccp_alpha values\n",
    "acc = dtc_cv_acc.cv_results_['mean_test_score']\n",
    "ccp = dtc_cv_acc.cv_results_['param_ccp_alpha'].data\n",
    "\n",
    "pd.DataFrame({'ccp lpha': ccp, 'Validation Accuracy': acc}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392bf7c",
   "metadata": {},
   "source": [
    "Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def bootstrap_validation(test_data, test_label, train_label, model, metrics_list, sample=500, random_state=66):\n",
    "    tic = time.time()\n",
    "    n_sample = sample\n",
    "    n_metrics = len(metrics_list)\n",
    "    output_array=np.zeros([n_sample, n_metrics])\n",
    "    output_array[:]=np.nan\n",
    "    print(output_array.shape)\n",
    "    for bs_iter in range(n_sample):\n",
    "        bs_index = np.random.choice(test_data.index, len(test_data.index), replace=True)\n",
    "        bs_data = test_data.loc[bs_index]\n",
    "        bs_label = test_label.loc[bs_index]\n",
    "        bs_predicted = model.predict(bs_data)\n",
    "        for metrics_iter in range(n_metrics):\n",
    "            metrics = metrics_list[metrics_iter]\n",
    "            output_array[bs_iter, metrics_iter]=metrics(bs_predicted,bs_label,train_label)\n",
    "#         if bs_iter % 100 == 0:\n",
    "#             print(bs_iter, time.time()-tic)\n",
    "    output_df = pd.DataFrame(output_array)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b914ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr(predictions):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions)\n",
    "    return tp/(tp + fn)\n",
    "\n",
    "def fpr(predictions):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions)\n",
    "    return fp/(fp + tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91617c6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bs_output_logreg = bootstrap_validation(X_test, y_test,y_train, logreg, metrics_list =[tpr], sample = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f923c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645a1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faffc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
